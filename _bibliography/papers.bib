---
---

@string{aps = {American Physical Society,}}

@misc{chebly2025strong,
    title={Strong, Accurate, and Low-Cost Robot Manipulator},
    author={Georges Chebly and Spencer Little and Nisal Perera and Aliya Abedeen and Ken Suzuki and Donghyun Kim},
    year={2025},
    eprint={2507.15693},
    archivePrefix={arXiv},
    primaryClass={cs.RO},
    html={https://arxiv.org/abs/2507.15693}, 
    video={https://www.youtube.com/watch?v=GcvvQRCKNxQ},
    preview={forte.jpg},
}

@INPROCEEDINGS{perera2024staccatoesinglelegrobotmimics,
  author={Nisal Perera and Shangqun Yu and Daniel Marew and Mack Tang and Ken Suzuki and Aidan McCormack and Shifan Zhu and Yong-Jae Kim and Donghyun Kim},
  booktitle={2024 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}, 
  title={StaccaToe: A Single-Leg Robot that Mimics the Human Leg and Toe}, 
  year={2024},
  volume={},
  number={},
  pages={755-761},
  html={https://arxiv.org/abs/2404.05039}, 
  video={https://www.youtube.com/watch?v=jZwrF528Fg0},
  preview={staccatoe.gif},
  selected={true},
  }


@INPROCEEDINGS{yu2024learninggenericdynamiclocomotion,
  author={Shangqun Yu and Nisal Perera and Daniel Marew and Donghyun Kim},
  booktitle={2024 IEEE-RAS 23rd International Conference on Humanoid Robots (Humanoids)}, 
  title={Learning Generic and Dynamic Locomotion of Humanoids Across Discrete Terrains}, 
  year={2024},
  volume={},
  number={},
  pages={755-761},
  html={https://arxiv.org/abs/2405.17227},
  video={https://www.youtube.com/watch?v=h0k11Ess_kc},
  preview={tello.gif},
  selected={true}, 
  }

  @INPROCEEDINGS{marew2024biomechanicsinspiredapproachsoccerkicking,
      title={A Biomechanics-Inspired Approach to Soccer Kicking for Humanoid Robots}, 
      booktitle={2024 IEEE-RAS 23rd International Conference on Humanoid Robots (Humanoids)}, 
      author={Daniel Marew and Nisal Perera and Shangqun Yu and Sarah Roelker and Donghyun Kim},
      year={2024},
      eprint={2407.14612},
      archivePrefix={arXiv},
      primaryClass={cs.RO},
      html={https://arxiv.org/abs/2407.14612}, 
      video={https://www.youtube.com/watch?v=Tx7TbmW85Yk},
      preview={kick.gif} ,
      selected={true}, 
}



  @article{zhu2023dynamic,
  bibtex_show={true},
  preview={iros-w.gif},
  abstract={As robots increase in agility and encounter fast- moving objects, dynamic object detection and avoidance become notably challenging. Traditional RGB cameras, burdened by motion blur and high latency, often act as the bottleneck. Event cameras have recently emerged as a promising solution for the challenges related to rapid movement. In this paper, we introduce a dynamic object avoidance framework that integrates both event and RGBD cameras. Specifically, this framework first estimates and compensates for the eventâ€™s motion to detect dynamic objects. Subsequently, depth data is combined to derive a 3D trajectory. When initiating from a static state, the robot adjusts its height based on the predicted collision point to avoid the dynamic obstacle. Through real-world experiments with the Mini-Cheetah, our approach successfully circumvents dynamic objects at speeds up to 5 m/s, achieving an 83% success rate.
Supplemental video: },
  title={Dynamic Object Avoidance using Event-Data for a Quadruped Robot},
  author={Zhu, Shifan and Perera, Nisal and Yu, Shangqun and Hwang, Hochul and Kim, Donghyun},
  journal={IROS IPPC Workshop},
  year={2023},
  video={https://www.youtube.com/watch?v=wEPvynkVlLA},
  html={https://ippc-iros23.github.io/papers/zhu.pdf},
  selected={true},
}




